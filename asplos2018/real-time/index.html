<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://parallel-ml.github.io/docs/asplos2018/real-time/">
    <link rel="shortcut icon" href="../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>ASPLOS 2018 - SARAV Documentaion</title>
    <link href="../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../css/highlight.css">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../js/jquery-3.2.1.min.js"></script>
    <script src="../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Introduction", url: "#_top", children: [
          ]},
          {title: "Installation", url: "#installation", children: [
              {title: "Single device (GPU and CPU).", url: "#single-device-gpu-and-cpu" },
              {title: "Multiple devices (CPU and RPC).", url: "#multiple-devices-cpu-and-rpc" },
          ]},
          {title: "Quick Start", url: "#quick-start", children: [
              {title: "Single device (GPU and CPU)", url: "#single-device-gpu-and-cpu_1" },
              {title: "Multiple devices (CPU and RPC)", url: "#multiple-devices-cpu-and-rpc_1" },
              {title: "Refereces", url: "#refereces" },
          ]},
        ];

    </script>
    <script src="../../js/base.js"></script>
      <script src="../../search/main.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../../people/people/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../../people/people/" class="btn btn-xs btn-link">
        People
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../../fpga/split-networks/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../../fpga/split-networks/" class="btn btn-xs btn-link">
        FPGA
      </a>
    </div>
    
  </div>

    

    <h2 id="introduction">Introduction</h2>
<p>This is demo of <strong>Real-Time Image Recognition Using Collaborative IoT Devices</strong> at <strong>ACM ReQuEST workshop co-located with ASPLOS 2018</strong></p>
<p><a href="https://github.com/parallel-ml/asplos2018-workshop">Github repo</a></p>
<p>This repository contains demo files for demonstration of Musical Chair[1] applied on two state-of-art 
deep learning neural networks, AlexNet[2] and VGG16[3].</p>
<h2 id="installation">Installation</h2>
<p>Please make sure that you have <b>Python 2.7</b> running on your device. We have
two versions of model inference. One is using GPU and running model inference on
single machine. Another is using CPU and using RPC to off-shore the computation
to other devices. We will have different installation guide for those two versions
model inference. </p>
<h3 id="single-device-gpu-and-cpu">Single device (GPU and CPU).</h3>
<p><em>(This is NVidia Jetson TX2 version in our paper)</em></p>
<p>Dependencies:
* tensorflow-gpu &gt;= 1.5.0
* Keras &gt;= 2.1.3</p>
<pre><code class="angular2html">pip install keras
</code></pre>

<p><a href="https://github.com/keras-team/keras">Please refer to official installation guideline from Keras for more information</a></p>
<h3 id="multiple-devices-cpu-and-rpc">Multiple devices (CPU and RPC).</h3>
<p><em>(This is Raspberry PI 3 versions in our paper)</em></p>
<p>Dependencies:
* tensorflow &gt;= 1.5.0
* Keras &gt;= 2.1.3
* avro &gt;= 1.8.2</p>
<p>We have provided dependency file here. You can execute this file to install packages.</p>
<pre><code class="angular2html">pip install -r requirements.txt
</code></pre>

<h2 id="quick-start">Quick Start</h2>
<h3 id="single-device-gpu-and-cpu_1">Single device (GPU and CPU)</h3>
<p><em>(This is NVidia Jetson TX2 version in our paper)</em></p>
<h4 id="gpu-version">GPU Version</h4>
<p>Execute predict file to run model inference. </p>
<pre><code>python predict.py
</code></pre>

<h4 id="cpu-version">CPU Version</h4>
<pre><code>CUDA_VISIBLE_DEVICES= python predict.py
</code></pre>

<h3 id="multiple-devices-cpu-and-rpc_1">Multiple devices (CPU and RPC)</h3>
<p><em>(This is Raspberry PI 3 versions in our paper)</em></p>
<p>We make a checklist for you before running our program.
- [ ] Have all correct packages installed on Raspberry Pi. 
- [ ] The Raspberry PI has port 12345, 9999 open. 
- [ ] Put correct IP address in IP table file <code>mutiple-devices/alexnet/resource/ip</code>. 
The IP table file is in <code>json</code> format. </p>
<h4 id="alexnet">AlexNet</h4>
<p>For AlexNet, we have same model partition, so we will use the same node file for 
different system setup. The IP table is default to 4 devices setup. You need to 
add 1 more IP address to <code>block1</code> if you want to test 6 devices setup.</p>
<p><img alt="alexnet" src="https://github.com/parallel-ml/asplos2018-workshop/blob/master/figs/alexnet-nodes.png" /></p>
<ul>
<li>On all of your device except the initial sender, run the node.</li>
</ul>
<pre><code class="angular2html">python node.py
</code></pre>

<ul>
<li>Start the data sender. You should be able to see console log.</li>
</ul>
<pre><code class="angular2html">python initial.py
</code></pre>

<ul>
<li>If you modify our code, you can use flag to debug.</li>
</ul>
<pre><code class="angular2html">python node.py -d
</code></pre>

<h4 id="vgg16">VGG16</h4>
<p>For VGG16, we have different model separation for different system setup, so we put
two directories under <code>mutiple-devices/vgg16</code>. For <code>8devices</code>, you should have 3 devices for
<b>block234</b> and 2 devices for <b>fc1</b>, which means you need 2 IP addresses for those
2 blocks in IP table. For <code>11devices</code>, you should have 7 devices for <b>block12345</b>,
so put 7 IP addresses at IP table. </p>
<p><img alt="vgg16" src="https://github.com/parallel-ml/asplos2018-workshop/blob/master/figs/vgg-8nodes.png" /></p>
<ul>
<li>On all of your device except the initial sender, run the node.</li>
</ul>
<pre><code class="angular2html">python node.py
</code></pre>

<ul>
<li>Start the data sender. You should be able to see console log.</li>
</ul>
<pre><code class="angular2html">python initial.py
</code></pre>

<h3 id="refereces">Refereces</h3>
<p>[1]: R. Hadidi, J. Cao, M. Woodward, M. Ryoo, and H. Kim, "Musical Chair: Efficient Real-Time Recognition Using Collaborative IoT Devices," ArXiv e-prints:1802.02138.</p>
<p>[2]: A. Krizhevsky, I. Sutskever, and G. E. Hinton, "Imagenet Classification With Deep Convolutional Neural Networks}," in Advances in Neural InformationProcessing Systems (NIPS), pp. 1097--1105, 2012.</p>
<p>[3]: K. Simonyan and A. Zisserman, "Very Deep Convolutional Networks for Large-Scale Image Recognition," in International Conference onLearning Representations (ICLR), 2015.</p>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../../people/people/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../../people/people/" class="btn btn-xs btn-link">
        People
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../../fpga/split-networks/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../../fpga/split-networks/" class="btn btn-xs btn-link">
        FPGA
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="">Windmill Dark</a> theme by None (noraj).</p>
</footer>

</body>
</html>