<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>FPGA - distributed cloud ML</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "FPGA";
    var mkdocs_page_input_path = "fpga\\split-networks.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> distributed cloud ML</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Getting Started</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../getting-started/setting-up-pi/">Connecting to Raspberry Pi</a>
                </li>
                <li class="">
                    
    <a class="" href="../../getting-started/speaker-mic/">Setting Up Speaker and Mic</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Cameras</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../camera/picamera/">Using the PiCamera</a>
                </li>
                <li class="">
                    
    <a class="" href="../../camera/webcam/">Webcam video/image</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">IMU (GPS, Accelerometer)</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../imu/gps/">GPS (Neo 6M GPS)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../imu/imu/">IMU (Berry IMU)</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Vision System</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../vision/character/">Character Recognition</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Speech Recognition</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../speech/deepspeech/">Deepspeech</a>
                </li>
                <li class="">
                    
    <a class="" href="../../speech/sphinx/">Sphinx</a>
                </li>
                <li class="">
                    
    <a class="" href="../../speech/text-to-speech/">Text to Speech</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Mapping</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../mapping/lidar-slam/">Lidar</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Visual SLAM</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../visual_slam/webcam-information/">Webcam Information</a>
                </li>
                <li class="">
                    
    <a class="" href="../../visual_slam/installing-docker-on-pi/">Installing Docker on the Raspberry Pi</a>
                </li>
                <li class="">
                    
    <a class="" href="../../visual_slam/live-streaming-pi-video/">Live Streaming Raspberry Pi Video</a>
                </li>
                <li class="">
                    
    <a class="" href="../../visual_slam/calibration/">Camera Calibration</a>
                </li>
                <li class="">
                    
    <a class="" href="../../visual_slam/running-slam/">Running SLAM</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">iRobot</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../irobot/keyboard/">Keyboard Control</a>
                </li>
                <li class="">
                    
    <a class="" href="../../irobot/navi_lidar_voice/">Navigation with Lidar/Voice</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">FPGA</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#fpl19-split-networks-on-fpga">FPL19 Split Networks on FPGA</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#motivation">Motivation</a></li>
        
            <li><a class="toctree-l3" href="#code-description">Code Description</a></li>
        
            <li><a class="toctree-l3" href="#setup">Setup</a></li>
        
            <li><a class="toctree-l3" href="#usage">Usage</a></li>
        
        </ul>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../asplos2018/real-time/">ASPLOS 2018</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../people/people/">People</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../adhoc/adhoc/">Adhoc Network</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">distributed cloud ML</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
    
    <li>FPGA</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="fpl19-split-networks-on-fpga">FPL19 Split Networks on FPGA</h1>
<p>Implementation of a split, distributed CNN (ResNet V1 18), deployed to 2 <a href="https://pynq.io">PYNQ FPGA boards</a> using <a href="https://tvm.ai">TVM/VTA</a>.</p>
<p>Github repo is available <a href="https://github.com/parallel-ml/Capella-FPL19-SplitNetworksOnFPGA">here</a>.</p>
<h2 id="motivation">Motivation</h2>
<p>Implementation of deep neural networks (DNNs) are hard to achieve on edge devices because DNNs
often require more resources than those provided by individual edge devices.</p>
<p>The idea of this project is to create an edge-tailored model by splitting a DNN into independent narrow DNNs to run
separately on multiple edge devices in parallel.</p>
<p>The outputs from the split networks are then
concatenated and fed through the fully connected layers to perform inference.</p>
<h2 id="code-description">Code Description</h2>
<ul>
<li><code>splitnet.py</code> contains split models built with <a href="https://mxnet.incubator.apache.org/versions/master/gluon/index.html">MxNet Gluon</a>. Only <code>resnet18_v1_split</code> is implemented so far.</li>
<li><code>resnet18_v1_split</code> returns a split version of <code>mxnet.gluon.model_zoo.vision.resnet18_v1</code>; initialized with random weights.</li>
<li><code>demo.py</code> demonstrates how to deploy split networks to 2 PYNQ FPGA boards with TVM/VTA and how to concatenate the results.</li>
<li><code>autotune.py</code> uses TVM's autotuning tool to achieve fast performance when running <code>resnet18_v1_split</code> on PYNQ FPGA. Currently broken.</li>
</ul>
<h2 id="setup">Setup</h2>
<h3 id="pynq-boards">PYNQ Boards</h3>
<p>To deploy the split networks, first acquire 2 PYNQ boards
and set them up following instructions <a href="https://pynq.readthedocs.io/en/latest/getting_started/pynq_z1_setup.html">here</a>.</p>
<p>After PYNQ boards are set up, follow instructions <a href="https://docs.tvm.ai/vta/install.html#pynq-side-rpc-server-build-deployment">here</a> to
launch TVM-based RPC servers on both boards. You should see the following output when starting the RPC server:</p>
<pre><code>INFO:root:RPCServer: bind to 0.0.0.0:9091
</code></pre>

<p>The RPC server should be listening on port <code>9091</code>.</p>
<h3 id="local">Local</h3>
<p>The following instructions apply to your local machine. CNN models are developed, compiled
&amp; uploaded to PYNQ boards <em>from your local machine</em> via RPC.</p>
<p>First, install TVM with LLVM enabled. Follow the instructions <a href="https://docs.tvm.ai/install/from_source.html">here</a>.</p>
<p>Install the necessary python dependencies:</p>
<pre><code>pip3 install --user numpy decorator attrs
</code></pre>

<p>Next, you need to add a configuration file for VTA:</p>
<pre><code>cd &lt;tvm root&gt;
cp vta/config/pynq_sample.json vta/config/vta_config.json
</code></pre>

<p>When the TVM compiler compiles the convolutional operators in a neural network, it queries a log file to
get the best knob parameters to achieve fast performance. Normally, for a particular network, this log file
is generated using TVM's autotuning tool (<code>autotune.py</code>).</p>
<p>However, since this tool seems to be broken, log file
for <code>resnet18_v1_split</code> was manually created.</p>
<p>Move this log file to where the compiler can find it:</p>
<pre><code>cd &lt;project root&gt;
cp vta_v0.05.log ~/.tvm/tophub/vta_v0.05.log
</code></pre>

<h2 id="usage">Usage</h2>
<p>After setup has been complete on both the PYNQ and host end, you are
now ready to deploy the split networks. <code>demo.py</code> is a minimal example that shows you how to do this.</p>
<p>First, install additional Python dependencies:</p>
<pre><code>pip3 install --user mxnet pillow
</code></pre>

<p>Then run the demo:</p>
<pre><code>python3 demo.py [--cpu] [--nonsplit] [--i]
</code></pre>

<h3 id="options">Options:</h3>
<ul>
<li>
<p><code>--cpu</code> Run model on local machine instead of PYNQ boards.</p>
</li>
<li>
<p><code>--nonsplit</code> Run the non-split version of the model.</p>
</li>
<li>
<p><code>--i</code> Run the interactive version of the demo. This allows you to enter paths to image files to feed to model.</p>
</li>
</ul>
<p>By default, the demo downloads 50 images of animals from Google Images, feeds them to the model, and reports the mean and standard deviation (in sec) of the inference delays. </p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../asplos2018/real-time/" class="btn btn-neutral float-right" title="ASPLOS 2018">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../../irobot/navi_lidar_voice/" class="btn btn-neutral" title="Navigation with Lidar/Voice"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../../irobot/navi_lidar_voice/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../../asplos2018/real-time/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>

</body>
</html>
