<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Sphinx - distributed cloud ML</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Sphinx";
    var mkdocs_page_input_path = "speech\\sphinx.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> distributed cloud ML</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Getting Started</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../getting-started/setting-up-pi/">Connecting to Raspberry Pi</a>
                </li>
                <li class="">
                    
    <a class="" href="../../getting-started/speaker-mic/">Setting Up Speaker and Mic</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Cameras</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../camera/picamera/">Using the PiCamera</a>
                </li>
                <li class="">
                    
    <a class="" href="../../camera/webcam/">Webcam video/image</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">IMU (GPS, Accelerometer)</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../imu/gps/">GPS (Neo 6M GPS)</a>
                </li>
                <li class="">
                    
    <a class="" href="../../imu/imu/">IMU (Berry IMU)</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Vision System</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../vision/character/">Character Recognition</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Speech Recognition</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../deepspeech/">Deepspeech</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">Sphinx</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#cmu-sphinx">CMU Sphinx</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#example-of-running-in-terminal">Example of Running in Terminal</a></li>
        
            <li><a class="toctree-l4" href="#installation">Installation</a></li>
        
            <li><a class="toctree-l4" href="#example-of-running-with-c">Example of Running with C</a></li>
        
            <li><a class="toctree-l4" href="#system-mic-noise-fix">System Mic Noise Fix</a></li>
        
        </ul>
    

    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../text-to-speech/">Text to Speech</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Mapping</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../mapping/lidar-slam/">Lidar</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Visual SLAM</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../visual_slam/webcam-information/">Webcam Information</a>
                </li>
                <li class="">
                    
    <a class="" href="../../visual_slam/installing-docker-on-pi/">Installing Docker on the Raspberry Pi</a>
                </li>
                <li class="">
                    
    <a class="" href="../../visual_slam/live-streaming-pi-video/">Live Streaming Raspberry Pi Video</a>
                </li>
                <li class="">
                    
    <a class="" href="../../visual_slam/calibration/">Camera Calibration</a>
                </li>
                <li class="">
                    
    <a class="" href="../../visual_slam/running-slam/">Running SLAM</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">iRobot</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../irobot/keyboard/">Keyboard Control</a>
                </li>
                <li class="">
                    
    <a class="" href="../../irobot/navi_lidar_voice/">Navigation with Lidar/Voice</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../fpga/split-networks/">FPGA</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../asplos2018/real-time/">ASPLOS 2018</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../people/people/">People</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">distributed cloud ML</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Speech Recognition &raquo;</li>
        
      
    
    <li>Sphinx</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="cmu-sphinx">CMU Sphinx</h1>
<p>Authors: Ramyad, Sayuj<br />
Date: 7/25/2019</p>
<p>Fast Setup:</p>
<pre><code>git clone https://github.com/parallel-ml/sphinxSpeech2Text
./install.sh
make
./decode
</code></pre>

<p>Parallel-ml repo: <a href="https://github.com/parallel-ml/sphinxSpeech2Text">https://github.com/parallel-ml/sphinxSpeech2Text</a></p>
<p>I used the pocketsphinx to decode the audio files on the raspberry pi’s. I installed it on the raspberry pi by following these instructions: <a href="https://cmusphinx.github.io/wiki/tutorialpocketsphinx/#installation-on-unix-system">link</a></p>
<p>Then I used the pocketsphinx_continuous command line command. There are multiple options, such as <code>-inmic</code>, which while use the system’s default microphone to detect and live decode the speech. You can also decode files using the <code>-infile</code> flag, then type the directory of the file relative to where you are calling the command from.</p>
<p>You can change the dictionary and the language model that the program uses by using the <code>-dict</code> and <code>-lm</code> flags. I created my own dictionary an language model using a tool I found online <a href="http://www.speech.cs.cmu.edu/tools/lmtool-new.html">link</a>, specifically made for pocketsphinx. I did this so that we could reduce the language model size to improve performance and accuracy. I found that the performance was 6x faster when I used my reduced dictionary, and obviously the accuracy is better, but it loses flexibility.</p>
<p>The next steps are to increase the dictionary to include a more variety of words, and increase the flexibility of commands that can be given to the raspberry pi. Below I have attached pictures of terminal output that shows the difference in performance. The output on the top shows performance with smaller dictionary and language model, the output on the bottom is the original dictionary that pocketsphinx comes with. It took more than 6x longer and it was less accurate.</p>
<pre><code class="BASH">pi@n1:/Research$ ./decode.out  
MOVE DOWN  
MOVE UP  
TURN TO ME  
Time Elapsed: 2.049368  


pi@n1:/Research$ ./decode.out  
uh got caught  
move up  
learn to make  
Time Elapsed: 2.049368  
</code></pre>

<p>Originally it verbosely outputs every step while it processes the audio, and it was hard to find the actual output, so I created a command to output all the unwanted logs to a specific file, and the actual decoded speech into it’s own file.</p>
<h3 id="example-of-running-in-terminal">Example of Running in Terminal</h3>
<pre><code class="BASH">pocketsphinx_continuous -infile testfiles/Untitled.wav -dict dicts/8050.dic -lm dicts/8050.lm
</code></pre>

<p>Note: If you get an error such as: <code>error while loading shared libraries: libpocketsphinx.so.3</code>, you may want to check your linker configuration of the LD_LIBRARY_PATH environment variable described below:</p>
<pre><code class="BASH">export LD_LIBRARY_PATH=/usr/local/lib
export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
</code></pre>

<h3 id="installation">Installation</h3>
<pre><code class="BASH">sudo apt-get install bison
sudo apt-get install swig
cd sphinxbase-5prealpha
./autogen.sh
.configure
make
sudo make install
export LD_LIBRARY_PATH=/usr/local/lib
export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
cd ../pocketsphinx-5prealpha
./autogen.sh
.configure
make
sudo make install
</code></pre>

<h3 id="example-of-running-with-c">Example of Running with C</h3>
<p>Contents of decode.c</p>
<pre><code class="BASH">gcc -o decode decode.c
</code></pre>

<pre><code class="CPP">#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;time.h&gt;
#define BILLION  1000000000.0;


int main(void) {
    struct timespec start, end;

    system(&quot;export LD_LIBRARY_PATH=/usr/local/lib&quot;);
    system(&quot;arecord --format=S16_LE --duration=5 --rate=16k -D sysdefault:CARD=1 --file-type=wav testfiles/noisy.wav&quot;);
    system(&quot;echo done recording...&quot;);
    system(&quot;python testfiles/noiseClean.py&quot;);
    system(&quot;echo done cleaning...&quot;);
    clock_gettime(CLOCK_REALTIME, &amp;start);
    system(&quot;\
        pocketsphinx_continuous \
        -infile testfiles/filtered.wav \
        -dict dicts/8050.dic \
        -lm dicts/8050.lm \
        2&gt;./output/unwanted-stuff.log | tee ./output/words.txt&quot;);
    // pocketsphinx_continuous -infile testfiles/Untitled.wav -dict dicts/8050.dic -lm dicts/8050.lm 2&gt;./output/unwanted-stuff.log | tee ./output/words.txt
    system(&quot;echo done decoding...&quot;);
    clock_gettime(CLOCK_REALTIME, &amp;end);
    double time_spent = (end.tv_sec - start.tv_sec) +
            (end.tv_nsec - start.tv_nsec) / BILLION;
    char *timerOutput = malloc(25);
    sprintf(timerOutput, &quot;echo Time Elapsed: %f\n&quot;, time_spent);
    system(timerOutput);
}
</code></pre>

<h3 id="system-mic-noise-fix">System Mic Noise Fix</h3>
<p>Using system/USB mic has noises, to clean, here is the content of noiseClean.py:</p>
<pre><code class="python">outname = 'testfiles/filtered.wav'

cutOffFrequency = 400.0

# from http://stackoverflow.com/questions/13728392/moving-average-or-running-mean
def running_mean(x, windowSize):
  cumsum = np.cumsum(np.insert(x, 0, 0))
  return (cumsum[windowSize:] - cumsum[:-windowSize]) / windowSize

# from http://stackoverflow.com/questions/2226853/interpreting-wav-data/2227174#2227174
def interpret_wav(raw_bytes, n_frames, n_channels, sample_width, interleaved = True):

    if sample_width == 1:
        dtype = np.uint8 # unsigned char
    elif sample_width == 2:
        dtype = np.int16 # signed 2-byte short
    else:
        raise ValueError(&quot;Only supports 8 and 16 bit audio formats.&quot;)

    channels = np.fromstring(raw_bytes, dtype=dtype)

    if interleaved:
        # channels are interleaved, i.e. sample N of channel M follows sample N of channel M-1 in raw data
        channels.shape = (n_frames, n_channels)
        channels = channels.T
    else:
        # channels are not interleaved. All samples from channel M occur before all samples from channel M-1
        channels.shape = (n_channels, n_frames)

    return channels

with contextlib.closing(wave.open(fname,'rb')) as spf:
    sampleRate = spf.getframerate()
    ampWidth = spf.getsampwidth()
    nChannels = spf.getnchannels()
    nFrames = spf.getnframes()

    # Extract Raw Audio from multi-channel Wav File
    signal = spf.readframes(nFrames*nChannels)
    spf.close()
    channels = interpret_wav(signal, nFrames, nChannels, ampWidth, True)

    # get window size
    # from http://dsp.stackexchange.com/questions/9966/what-is-the-cut-off-frequency-of-a-moving-average-filter
    freqRatio = (cutOffFrequency/sampleRate)
    N = int(math.sqrt(0.196196 + freqRatio**2)/freqRatio)

    # Use moviung average (only on first channel)
    filtered = running_mean(channels[0], N).astype(channels.dtype)

    wav_file = wave.open(outname, &quot;w&quot;)
    wav_file.setparams((1, ampWidth, sampleRate, nFrames, spf.getcomptype(), spf.getcompname()))
    wav_file.writeframes(filtered.tobytes('C'))
    wav_file.close()
</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../text-to-speech/" class="btn btn-neutral float-right" title="Text to Speech">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../deepspeech/" class="btn btn-neutral" title="Deepspeech"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../deepspeech/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../text-to-speech/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>

</body>
</html>
